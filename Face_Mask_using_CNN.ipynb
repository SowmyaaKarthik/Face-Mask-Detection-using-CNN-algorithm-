{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/3p+sVvVZ5zs8j1SMOckM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SowmyaaKarthik/Face-Mask-Detection-using-CNN-algorithm-/blob/main/Face_Mask_using_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90s4ztJJHj0u"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd                               \n",
        "import numpy as np                                \n",
        "import tensorflow as tf                           \n",
        "from tensorflow import keras                      \n",
        "from tensorflow.keras.models import Sequential    \n",
        "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D,Dropout  \n",
        "from tensorflow.keras.optimizers import Adam      #Adam optimizer\n",
        "from keras.preprocessing import image             #used for image classification\n",
        "from keras.preprocessing.image import ImageDataGenerator  #used to expand the training dataset in order to improve the performance and ability of the model to generalize\n",
        "import matplotlib.pyplot as plt                   #library to plot graphs\n",
        "from google.colab import files                    #To be able to upload files\n",
        "\n",
        "\"\"\"Here I will upload the dataset file called `\"data\"` that has 2 subfolders `\"with\"` and `\"without`\" and unzip\"\"\"\n",
        "\n",
        "#upload file\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#unzipping the folder\n",
        "!unzip data.zip\n",
        "\n",
        "#delete the zip file as it is not needed anymore\n",
        "!rm data.zip\n",
        "\n",
        "# setting the batch size and the epochs\n",
        "\n",
        "batch_size = 8\n",
        "epochs = 30\n",
        "\n",
        "\"\"\"Splitting the images (80% training and 20% \n",
        "validation) and Data augmanting it\n",
        "\"\"\"\n",
        "\n",
        "directory = 'data'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCGjftn5KM7j",
        "outputId": "09592fbf-8179-4f62-a070-f4d999372edd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open data.zip, data.zip.zip or data.zip.ZIP.\n",
            "rm: cannot remove 'data.zip': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(validation_split=0.2,        # Splits the data into training (80%) and validation (20%)\n",
        "                                   rescale = 1./255,            # Multiple the colors by a number between 0-1 to process data faster\n",
        "                                   rotation_range=40,           #rotate the images\n",
        "                                   width_shift_range=0.2,     \n",
        "                                   height_shift_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')        #add new pixels when the image is rotated or shifted\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "                                directory,\n",
        "                                target_size = (70, 70),\n",
        "                                batch_size = batch_size,\n",
        "                                color_mode=\"rgb\",               # for coloured images\n",
        "                                class_mode = 'binary',\n",
        "                                seed=2020,                      # to make the result reproducible\n",
        "                                subset = 'training')            # Specify this is training set"
      ],
      "metadata": {
        "id": "7lZwXyUgKU7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = train_datagen.flow_from_directory(\n",
        "                                directory,\n",
        "                                target_size = (70, 70),\n",
        "                                batch_size = batch_size,\n",
        "                                color_mode=\"rgb\",               # for coloured images\n",
        "                                class_mode = 'binary',\n",
        "                                subset = 'validation')            # Specify this is training set\n",
        "\n",
        "\"\"\"**Display a batch of the images used in the training and thier labels**\"\"\"\n",
        "\n",
        "#generate a batch of images and labels from the training set\n",
        "imgs, labels = next(train_generator)"
      ],
      "metadata": {
        "id": "W5NyW55gKafI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting function\n",
        "\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, batch_size, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#displaying the images and thier labels where as 0 with mask and 1 without mask\n",
        "plotImages(imgs);\n",
        "print(labels);\n"
      ],
      "metadata": {
        "id": "-Ur21SsdKjv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create the model layers\n",
        "\n",
        "model = Sequential([\n",
        "                    Conv2D(filters=32, kernel_size=(3,3),activation='relu',padding='same',input_shape=(70,70,3)),\n",
        "                    MaxPool2D(pool_size=(2,2), strides=2),\n",
        "                    Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding= 'same'),\n",
        "                    MaxPool2D(pool_size=(2,2), strides =2),\n",
        "                    Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding= 'same'),\n",
        "                    MaxPool2D(pool_size=(2,2), strides =2),\n",
        "                    Flatten(),\n",
        "                    Dense(units=64, activation= 'relu'),\n",
        "                    #means the output is 0,1 (the labels) and the P(c=0) +P(c=1) = 1 \n",
        "                    Dense(units=1, activation='sigmoid'), \n",
        "\n",
        "])\n",
        "\n",
        "#check out the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "56VPIG1iLGaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "9oorxGOHLf1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "history = model.fit(train_generator ,epochs = epochs,validation_data= validation_generator)"
      ],
      "metadata": {
        "id": "wOr0N81zLWsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the loss of validation and training \n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochstoplot = range(1,epochs+1)\n",
        "plt.plot(epochstoplot, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochstoplot, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-9w_c1yTW8I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the accuracy of validation and training \n",
        "accur_train = history.history['accuracy']\n",
        "accur_val = history.history['val_accuracy']\n",
        "plt.plot(epochstoplot, accur_train, 'g', label='Training accuracy')\n",
        "plt.plot(epochstoplot, accur_val, 'b', label='validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8-qFnFbKYM-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install image"
      ],
      "metadata": {
        "id": "MxZwBMELYgPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"### **4. Testing the CNN model**\"\"\"\n",
        "from keras.preprocessing import image\n",
        "import keras.utils as image\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "TGREEN =  '\\033[1;37;42m'\n",
        "TRED =    '\\033[1;37;41m'\n",
        "for i in range (1,17):\n",
        "  img_directory = str(i) + '.jpg'\n",
        "  img_pred = image.load_img(img_directory, target_size = (70, 70))\n",
        "  img_pred = image.img_to_array(img_pred)\n",
        "  img_pred = np.expand_dims(img_pred, axis = 0)\n",
        "\n",
        "  prediction = model.predict(img_pred)\n",
        "  display(Image(img_directory,width= 150, height=150))\n",
        "  print(\"\\n\")\n",
        "  if(int(prediction[0][0]) == 0):\n",
        "    print(TGREEN + \"The person is wearing a mask. \\n\")\n",
        "  else:\n",
        "    print(TRED + \"The person is not wearing a mask.\\n\")"
      ],
      "metadata": {
        "id": "aUyykEbYYXZE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}